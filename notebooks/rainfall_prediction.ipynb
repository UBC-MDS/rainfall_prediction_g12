{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c64e70-e4cf-4315-8ba7-f2e39ee1e564",
   "metadata": {},
   "source": [
    "# Rainfall Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df89c9a-6780-4146-9a18-3ff3651075f9",
   "metadata": {},
   "source": [
    "## Data Loading, combining and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749cc8c-0a34-421a-bbb7-88b1d8356b17",
   "metadata": {},
   "source": [
    "*Group 12*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c3eee-b960-4e9c-9626-20420c494c0d",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4addc-2450-4c45-9a00-45885ac7abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import rpy2.rinterface\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebe339-3ae5-408a-8614-427911855fca",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c27be8-f9b8-4e69-a039-236a2401c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data/raw/figsharerainfall/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6fec9-79f1-47ef-894e-280a4bbf232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a9263-9358-4b36-8277-0b33d3b2484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_dl = [\"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab417e-19b6-40f8-ad71-c8bbb0802d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, files_to_dl[0]), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fb752-10e2-4438-a1b1-b55ce6c6ca2f",
   "metadata": {},
   "source": [
    "## Combine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc1931-06fd-4059-b859-54411a349c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "exclude = \"observed_daily_rainfall_SYD.csv\"\n",
    "files = glob.glob('../data/raw/figsharerainfall/*.csv')\n",
    "df = pd.concat(\n",
    "    (pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'[A-Z][^_]+', file)[0])\n",
    "                for file in files if file is not exclude)\n",
    ")\n",
    "df.to_csv(\"../data/processed/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf04ef-5cf5-43f1-9132-fd48fedead83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/combined_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349db01c-c8b8-4c15-9bf5-8c14df4fce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711897d-a6b8-4ada-b6da-21ffda46576a",
   "metadata": {},
   "source": [
    "## Combine data csv on different machines\n",
    "\n",
    "- Compare observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545af876-270c-4812-92c8-487d3580475c",
   "metadata": {},
   "source": [
    "| Team Member   | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-------------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Vera Cui      | macOS            | 16GB| M1        | No     | 6min 39s   |\n",
    "| Lynn Wu       | macOS            | 8GB | M1        | Yes    |  6min 7s   |\n",
    "| Jasmine Ortega|  macOS         |  8GB |   M1   |  Yes   | 9min 56s     |\n",
    "| Maeve Shi   | MacOS Big Sur    | 8GB | 2.3 GHz Dual-Core Intel Core i5 | Yes |  7min 30s   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5181a6-af76-49a5-92e8-f7888a3a5713",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd152ed-e586-4bf9-8a1a-969d0300c136",
   "metadata": {},
   "source": [
    "##  Load csv and perform EDA on different machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16473c1e-7693-4325-a572-7aefdfad2d05",
   "metadata": {},
   "source": [
    "#### Baseline `read_csv` time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b72e02-8a89-4c05-b0db-c439d13d8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../data/processed/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854f838-df0a-4a31-8cb7-fa3e75ae91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa3c1b-e431-4d61-9f1e-91c64d0054f6",
   "metadata": {},
   "source": [
    "| Team Member   | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-------------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Vera Cui      |                  |     |           |        |            |\n",
    "| Lynn Wu       |                  |     |           |        |            |\n",
    "| Jasmine Ortega|  MacOS           |8GB  |    M1     |  yes   |1 min 9s    |\n",
    "| Yike Shi      |                  |     |           |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8d1fb-bd9b-4828-8ad8-2716f8d055a1",
   "metadata": {},
   "source": [
    "As is, the csv file took 1 minute and 46 seconds to load. From `.info()` we can see that the df consists of 6 columns all of the dtype `float64`. To reduce memory usage, we will first convert the data type to `float32` and `float16`, both which will reduce memory used, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730d928-2273-4ca8-a265-ebc3584087d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Memory usage with float64: {df.memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df.astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float16: {df.astype('float16', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179264ec-dfab-4523-a07e-63d69afa19b4",
   "metadata": {},
   "source": [
    "#### Approaches to reduce memory usage while performing the EDA: *changing datatype*\n",
    "##### Convert to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a88345-4aa9-4b6b-a4e5-1d64aadfd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtypes = {\"lat_min\" : \"float32\",\n",
    "         \"lat_max\" : \"float32\",\n",
    "         \"lon_min\" : \"float32\",\n",
    "         \"lon_max\" : \"float32\",\n",
    "         \"rain (mm/day)\" : \"float32\",\n",
    "          \"model\" : \"string\"\n",
    "        }\n",
    "\n",
    "df_float32 = pd.read_csv('../data/processed/combined_data.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8833c-b10b-438d-9a95-1041811d3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float32.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9198b5-8418-4bce-89d3-2f809e39143a",
   "metadata": {},
   "source": [
    "##### Convert to float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73beb98-cca7-47fc-b685-78ab450f9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtypes = {\"lat_min\" : \"float16\",\n",
    "         \"lat_max\" : \"float16\",\n",
    "         \"lon_min\" : \"float16\",\n",
    "         \"lon_max\" : \"float16\",\n",
    "         \"rain (mm/day)\" : \"float16\",\n",
    "        \"model\" : \"string\"\n",
    "        }\n",
    "\n",
    "df_float16 = pd.read_csv('../data/processed/combined_data.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1a5a6-0bb9-411e-8061-4b377656b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd6f23-6b85-4704-a74b-f5584568d67a",
   "metadata": {},
   "source": [
    "As demonstrated, changing `float64` to less precise datatypes reduced runtimes. Interestingly, it looks like `float16` (50s) took almost as long to load as the more precise `float32` (58s). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa601498-c69c-40c3-bae2-98a2b71dba8e",
   "metadata": {},
   "source": [
    "#### Approaches to reduce memory usage while performing the EDA: *Loading in chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cd17e-091f-4bb2-b505-f3cc87ba819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunk = pd.read_csv(\"../data/processed/combined_data.csv\", chunksize=10_000_000, iterator=True)\n",
    "df = pd.concat(chunk)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07380e-82ac-42bf-914f-9191b6b86a46",
   "metadata": {},
   "source": [
    "Loading the data in chunks of 10,000,000 reduced the loading time to 1min 7s. Let's combine the `float32` strategy with loading in chunks! (Note: we use `float32` instead of `float16` because half precision types are not supported when loading the data in chunks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58957a6-8563-4d6e-9218-9692852349d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\"lat_min\" : \"float32\",\n",
    "         \"lat_max\" : \"float32\",\n",
    "         \"lon_min\" : \"float32\",\n",
    "         \"lon_max\" : \"float32\",\n",
    "         \"rain (mm/day)\" : \"float32\",\n",
    "         \"model\" : \"string\"\n",
    "        }\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "chunk = pd.read_csv(\"../data/processed/combined_data.csv\", chunksize=10_000_000, iterator=True, dtype=dtypes)\n",
    "final_df = pd.concat(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222dff8-4c8b-4dac-988a-94e22e85e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511222cd-7019-4d42-a16d-b838c4c05fe9",
   "metadata": {},
   "source": [
    "We successfully reduced the load time from 1min 9s to 54.9s. \n",
    "\n",
    "\n",
    "**Optimized data loading:**\n",
    "\n",
    "| Team Member   | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-------------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Vera Cui      |                  |     |           |        |            |\n",
    "| Lynn Wu       |                  |     |           |        |            |\n",
    "| Jasmine Ortega|  MacOS           |8GB  |    M1     |  yes   |54.9s       |\n",
    "| Yike Shi      |                  |     |           |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edea565-c455-4ab1-a9b1-b72303d670f3",
   "metadata": {},
   "source": [
    "Now, we will load the data (optimized) and conduct a simple EDA in which we will count the number of each model in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23019ab1-0499-4983-b182-1831b732da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\"lat_min\" : \"float32\",\n",
    "         \"lat_max\" : \"float32\",\n",
    "         \"lon_min\" : \"float32\",\n",
    "         \"lon_max\" : \"float32\",\n",
    "         \"rain (mm/day)\" : \"float32\",\n",
    "         \"model\" : \"string\"\n",
    "        }\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "chunk = pd.read_csv(\"../data/processed/combined_data.csv\", chunksize=10_000_000, iterator=True, dtype=dtypes)\n",
    "final_df = pd.concat(chunk)\n",
    "\n",
    "# EDA\n",
    "model_count = final_df[\"model\"].value_counts()\n",
    "model_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eda75e-eab2-4e81-8f52-282427b06193",
   "metadata": {},
   "source": [
    "**Python data load + EDA time:**\n",
    "\n",
    "| Team Member   | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-------------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Vera Cui      |                  |     |           |        |            |\n",
    "| Lynn Wu       |                  |     |           |        |            |\n",
    "| Jasmine Ortega|  MacOS           |8GB  |    M1     |  yes   |58.5 s      |\n",
    "| Yike Shi      |                  |     |           |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ed75b-7f69-4380-b3e6-d64dd01a8613",
   "metadata": {},
   "source": [
    "It looks like it takes ~1 minute to load and execute the EDA using the datatype `float32` and loading in chunks of 10,000,0000. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071edabf-2a94-4fb3-b9e2-b0095b39a1bc",
   "metadata": {},
   "source": [
    "(We attempted to plot the value counts, however, it consistently crashed the kernel on Mac M1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ce174-bf9a-446d-a74f-d4b3b9198f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.data_transformers.disable_max_rows()\n",
    "# alt.renderers.enable('mimetype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ab182-b1d9-4688-8f55-b3155597c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this kills my kernel but you can try it lol \n",
    "# count_plot = alt.Chart(final_df).mark_bar().encode(x='model', y='count()')# this kills my kernel but you can try it lol \n",
    "# count_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c0fbe-df66-43e2-a94e-a6dde65978b8",
   "metadata": {},
   "source": [
    "#### Transform Python df to R Parquet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00e46c-897e-4547-a5f9-7769b96000e1",
   "metadata": {},
   "source": [
    "We chose to use a parquet file to transfer the dataframe from Python to R because parquet files work well with rarrow. rarrow is ideal because by default, it reads and processes data in chunks, which we saw greatly improved our CSV loading time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e68598-ba93-4803-b9d7-7905ec3ad45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet(\"../data/processed/combined_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6da09-5097-4690-b69a-e7a5e1b151ee",
   "metadata": {},
   "source": [
    "#### Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252f855-d57a-476b-8b68-5d038d0e4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9542f6-f35f-4003-bbc7-111abffdcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "%%R\n",
    "library(dplyr)\n",
    "library(arrow)\n",
    "\n",
    "\n",
    "df <- open_dataset(\"../data/processed/combined_data.parquet\") \n",
    "\n",
    "eda <- df |> count(model)\n",
    "eda\n",
    "\n",
    "result <- eda %>% collect\n",
    "print(result, n=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54904f-775c-4b3a-8637-6ab028953ea4",
   "metadata": {},
   "source": [
    "**R data load + EDA time:**\n",
    "\n",
    "| Team Member   | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-------------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Vera Cui      |                  |     |           |        |            |\n",
    "| Lynn Wu       |                  |     |           |        |            |\n",
    "| Jasmine Ortega|  MacOS           |8GB  |    M1     |  yes   |2.49 s      |\n",
    "| Yike Shi      |                  |     |           |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8defc-09ca-4a50-aa7a-f6811c44f2bf",
   "metadata": {},
   "source": [
    "Overall, using a parquet file to transfer a Python dataframe to R was extremely effective. Considering the sheer volume of data we have (62 million rows), it's amazing that R was able to compute value counts in 2.5 seconds! Compare to Python, which took 58.5 seconds to complete the same task. From this simple experiment alone, it is clear to see the value of using an optimized storage file like a parquet over a CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6cb00-4f69-40c9-8819-339a7d818960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing tidyverse took years so im not sure if this is executable either \n",
    "# %%R\n",
    "\n",
    "# library(ggplot2)\n",
    "# library(tidyverse)\n",
    "\n",
    "# count_eda <- result |>\n",
    "#             groupby(model) |>\n",
    "#             mutate(count = n())\n",
    "            \n",
    "# count_eda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
